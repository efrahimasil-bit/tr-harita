"""
üéØ GELƒ∞≈ûMƒ∞≈û Tƒ∞CARƒ∞ PORTF√ñY ANALƒ∞Z Sƒ∞STEMƒ∞ v3
- üó∫Ô∏è Profesyonel T√ºrkiye Haritasƒ± (app26 entegrasyonu)
- ü§ñ Ger√ßek ML Tahminleme & Deep Learning
- üìä Geli≈ümi≈ü Rakip Analizi (dark theme fix)
- üß† Yeni Analizler: Pareto, Volatilite, Fƒ±rsat Skoru, YoY Heatmap
- üöÄ AI √ñnerileri & Strateji Motoru
- üì± Responsive Dashboard
- üîÑ Real-time G√ºncelleme
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import warnings
from io import BytesIO
import json
import hashlib
import time
from scipy import stats
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, IsolationForest
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
import xgboost as xgb
import lightgbm as lgb

# Yeni importlar
try:
    import geopandas as gpd
    from shapely.geometry import LineString, MultiLineString, Point
    GEOPANDAS_AVAILABLE = True
except ImportError:
    GEOPANDAS_AVAILABLE = False
    st.warning("‚ö†Ô∏è geopandas y√ºkl√º deƒüil. Geli≈ümi≈ü harita √∂zelliƒüi devre dƒ±≈üƒ±.")

try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False
    st.warning("‚ö†Ô∏è prophet y√ºkl√º deƒüil. FB Prophet tahmini devre dƒ±≈üƒ±.")

warnings.filterwarnings("ignore")

# =============================================================================
# PAGE CONFIG - GELƒ∞≈ûMƒ∞≈û
# =============================================================================
st.set_page_config(
    page_title="Ticari Portf√∂y Analizi Pro",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://www.example.com',
        'Report a bug': 'https://www.example.com/bug',
        'About': "### Ticari Portf√∂y Analiz Sistemi v3\nProfesyonel ticari analiz platformu"
    }
)

# =============================================================================
# CSS (Dark Theme Optimized - GELƒ∞≈ûMƒ∞≈û)
# =============================================================================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&display=swap');
    
    * {
        font-family: 'Inter', sans-serif;
        scroll-behavior: smooth;
    }
    
    .stApp {
        background: linear-gradient(135deg, #0a0f1e 0%, #141b2d 50%, #1a2238 100%);
        min-height: 100vh;
    }
    
    .main-header {
        font-size: 3.8rem;
        font-weight: 900;
        text-align: center;
        padding: 2.5rem 0;
        background: linear-gradient(135deg, #ffd700 0%, #f59e0b 30%, #d97706 70%, #b45309 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-shadow: 0 0 50px rgba(255, 215, 0, 0.3);
        letter-spacing: -1.5px;
        position: relative;
        margin-bottom: 1rem;
    }
    
    .main-header::after {
        content: '';
        position: absolute;
        bottom: 1.5rem;
        left: 50%;
        transform: translateX(-50%);
        width: 200px;
        height: 4px;
        background: linear-gradient(90deg, transparent, #f59e0b, transparent);
        border-radius: 2px;
    }
    
    div[data-testid="stMetricValue"] {
        font-size: 2.9rem;
        font-weight: 900;
        background: linear-gradient(135deg, #60a5fa 0%, #3b82f6 33%, #8b5cf6 66%, #ec4899 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        position: relative;
    }
    
    div[data-testid="stMetricValue"]::before {
        content: '';
        position: absolute;
        top: -10px;
        left: -10px;
        right: -10px;
        bottom: -10px;
        background: linear-gradient(135deg, rgba(59, 130, 246, 0.1), rgba(139, 92, 246, 0.1));
        border-radius: 12px;
        z-index: -1;
        opacity: 0;
        transition: opacity 0.3s ease;
    }
    
    div[data-testid="metric-container"]:hover div[data-testid="stMetricValue"]::before {
        opacity: 1;
    }
    
    div[data-testid="metric-container"] {
        background: linear-gradient(145deg, rgba(30, 41, 59, 0.95), rgba(15, 23, 42, 0.95));
        padding: 2.2rem 1.8rem;
        border-radius: 18px;
        border: 1px solid rgba(59, 130, 246, 0.25);
        box-shadow: 0 10px 35px rgba(0, 0, 0, 0.4);
        backdrop-filter: blur(15px);
        transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        position: relative;
        overflow: hidden;
    }
    
    div[data-testid="metric-container"]::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 3px;
        background: linear-gradient(90deg, #3b82f6, #8b5cf6, #ec4899);
        opacity: 0.7;
    }
    
    div[data-testid="metric-container"]:hover {
        transform: translateY(-8px) scale(1.02);
        box-shadow: 0 20px 50px rgba(59, 130, 246, 0.3);
        border-color: rgba(59, 130, 246, 0.5);
    }
    
    .stTabs [data-baseweb="tab"] {
        color: #94a3b8;
        font-weight: 600;
        padding: 1.2rem 2.2rem;
        background: linear-gradient(145deg, rgba(30, 41, 59, 0.7), rgba(15, 23, 42, 0.7));
        border-radius: 12px 12px 0 0;
        margin: 0 0.3rem;
        transition: all 0.3s ease;
        border: 1px solid rgba(255, 255, 255, 0.05);
        position: relative;
        overflow: hidden;
    }
    
    .stTabs [data-baseweb="tab"]::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(59, 130, 246, 0.1), transparent);
        transition: left 0.6s ease;
    }
    
    .stTabs [data-baseweb="tab"]:hover::before {
        left: 100%;
    }
    
    .stTabs [data-baseweb="tab"]:hover {
        background: linear-gradient(145deg, rgba(59, 130, 246, 0.15), rgba(30, 41, 59, 0.8));
        color: #e0e7ff;
        transform: translateY(-2px);
    }
    
    .stTabs [data-baseweb="tab"][aria-selected="true"] {
        background: linear-gradient(135deg, #3b82f6 0%, #2563eb 30%, #1d4ed8 100%);
        color: white;
        box-shadow: 0 8px 25px rgba(59, 130, 246, 0.4);
        border-color: rgba(59, 130, 246, 0.3);
        transform: translateY(0);
    }
    
    h1, h2, h3, h4 {
        color: #f8fafc !important;
        font-weight: 700;
        text-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
    }
    
    h1 { font-size: 2.8rem !important; }
    h2 { font-size: 2.2rem !important; }
    h3 { font-size: 1.8rem !important; }
    
    p, span, div, label {
        color: #e2e8f0;
    }
    
    .stButton>button {
        background: linear-gradient(135deg, #3b82f6 0%, #2563eb 30%, #1d4ed8 100%);
        color: white;
        border: none;
        padding: 0.9rem 2.2rem;
        border-radius: 10px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 6px 18px rgba(59, 130, 246, 0.3);
        position: relative;
        overflow: hidden;
    }
    
    .stButton>button::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2), transparent);
        transition: left 0.6s ease;
    }
    
    .stButton>button:hover::before {
        left: 100%;
    }
    
    .stButton>button:hover {
        transform: translateY(-3px) scale(1.05);
        box-shadow: 0 12px 30px rgba(59, 130, 246, 0.5);
    }
    
    /* Dark theme table fix - GELƒ∞≈ûMƒ∞≈û */
    div[data-testid="stDataFrame"] table {
        background: linear-gradient(145deg, rgba(30, 41, 59, 0.95), rgba(15, 23, 42, 0.95)) !important;
        color: #f1f5f9 !important;
        border-radius: 12px;
        overflow: hidden;
        border: 1px solid rgba(59, 130, 246, 0.2);
    }
    
    div[data-testid="stDataFrame"] th {
        background: linear-gradient(135deg, rgba(15, 23, 42, 0.95), rgba(30, 41, 59, 0.95)) !important;
        color: #f1f5f9 !important;
        font-weight: 700 !important;
        padding: 1.2rem !important;
        border-bottom: 2px solid rgba(59, 130, 246, 0.3) !important;
    }
    
    div[data-testid="stDataFrame"] td {
        color: #f1f5f9 !important;
        border-color: rgba(148, 163, 184, 0.15) !important;
        padding: 0.9rem !important;
        transition: background-color 0.2s ease;
    }
    
    div[data-testid="stDataFrame"] tr:hover td {
        background-color: rgba(59, 130, 246, 0.1) !important;
    }
    
    /* Custom scrollbar */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    
    ::-webkit-scrollbar-track {
        background: rgba(30, 41, 59, 0.3);
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb {
        background: linear-gradient(135deg, #3b82f6, #8b5cf6);
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: linear-gradient(135deg, #60a5fa, #a78bfa);
    }
    
    /* Badge styles */
    .badge {
        display: inline-block;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
        font-size: 0.85rem;
        font-weight: 600;
        margin: 0.2rem;
    }
    
    .badge-success {
        background: linear-gradient(135deg, rgba(16, 185, 129, 0.2), rgba(16, 185, 129, 0.1));
        color: #10b981;
        border: 1px solid rgba(16, 185, 129, 0.3);
    }
    
    .badge-warning {
        background: linear-gradient(135deg, rgba(245, 158, 11, 0.2), rgba(245, 158, 11, 0.1));
        color: #f59e0b;
        border: 1px solid rgba(245, 158, 11, 0.3);
    }
    
    .badge-danger {
        background: linear-gradient(135deg, rgba(239, 68, 68, 0.2), rgba(239, 68, 68, 0.1));
        color: #ef4444;
        border: 1px solid rgba(239, 68, 68, 0.3);
    }
    
    .badge-info {
        background: linear-gradient(135deg, rgba(59, 130, 246, 0.2), rgba(59, 130, 246, 0.1));
        color: #3b82f6;
        border: 1px solid rgba(59, 130, 246, 0.3);
    }
    
    /* Card styles */
    .custom-card {
        background: linear-gradient(145deg, rgba(30, 41, 59, 0.95), rgba(15, 23, 42, 0.95));
        border-radius: 16px;
        padding: 1.8rem;
        border: 1px solid rgba(59, 130, 246, 0.25);
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        margin-bottom: 1.5rem;
        transition: all 0.3s ease;
    }
    
    .custom-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 12px 40px rgba(59, 130, 246, 0.2);
        border-color: rgba(59, 130, 246, 0.4);
    }
    
    /* Progress bars */
    .progress-container {
        background: rgba(30, 41, 59, 0.7);
        border-radius: 10px;
        height: 10px;
        overflow: hidden;
        margin: 0.5rem 0;
    }
    
    .progress-bar {
        height: 100%;
        border-radius: 10px;
        background: linear-gradient(90deg, #3b82f6, #8b5cf6);
        transition: width 0.5s ease;
    }
</style>
""", unsafe_allow_html=True)

# =============================================================================
# SESSION STATE Y√ñNETƒ∞Mƒ∞
# =============================================================================
if 'last_refresh' not in st.session_state:
    st.session_state.last_refresh = datetime.now()
if 'data_hash' not in st.session_state:
    st.session_state.data_hash = None
if 'cached_results' not in st.session_state:
    st.session_state.cached_results = {}
if 'ai_recommendations' not in st.session_state:
    st.session_state.ai_recommendations = {}
if 'user_preferences' not in st.session_state:
    st.session_state.user_preferences = {
        'theme': 'dark',
        'auto_refresh': False,
        'notifications': True,
        'default_product': 'TROCMETAM'
    }

# =============================================================================
# MAP MODULE - GELƒ∞≈ûMƒ∞≈û B√ñLGE RENKLERƒ∞
# =============================================================================
REGION_COLORS = {
    "MARMARA": "#0EA5E9",
    "BATI ANADOLU": "#14B8A6",
    "EGE": "#FCD34D",
    "ƒ∞√á ANADOLU": "#F59E0B",
    "G√úNEY DOƒûU ANADOLU": "#E07A5F",
    "KUZEY ANADOLU": "#059669",
    "KARADENƒ∞Z": "#059669",
    "AKDENƒ∞Z": "#8B5CF6",
    "DOƒûU ANADOLU": "#7C3AED",
    "Dƒ∞ƒûER": "#64748B"
}

FIX_CITY_MAP = {
    "AGRI": "AƒûRI",
    "BARTIN": "BARTIN",
    "BINGOL": "Bƒ∞NG√ñL",
    "DUZCE": "D√úZCE",
    "ELAZIG": "ELAZIƒû",
    "ESKISEHIR": "ESKƒ∞≈ûEHƒ∞R",
    "GUMUSHANE": "G√úM√ú≈ûHANE",
    "HAKKARI": "HAKKARƒ∞",
    "ISTANBUL": "ƒ∞STANBUL",
    "IZMIR": "ƒ∞ZMƒ∞R",
    "IGDIR": "IƒûDIR",
    "KARABUK": "KARAB√úK",
    "KINKKALE": "KIRIKKALE",
    "KIRSEHIR": "KIR≈ûEHƒ∞R",
    "KUTAHYA": "K√úTAHYA",
    "MUGLA": "MUƒûLA",
    "MUS": "MU≈û",
    "NEVSEHIR": "NEV≈ûEHƒ∞R",
    "NIGDE": "Nƒ∞ƒûDE",
    "SANLIURFA": "≈ûANLIURFA",
    "SIRNAK": "≈ûIRNAK",
    "TEKIRDAG": "TEKƒ∞RDAƒû",
    "USAK": "U≈ûAK",
    "ZINGULDAK": "ZONGULDAK",
    "CANAKKALE": "√áANAKKALE",
    "CANKIRI": "√áANKIRI",
    "CORUM": "√áORUM",
    "K. MARAS": "KAHRAMANMARA≈û"
}

# =============================================================================
# GELƒ∞≈ûMƒ∞≈û HELPER FUNCTIONS
# =============================================================================
def calculate_data_hash(df):
    """Veri hash'i hesapla - deƒüi≈üiklik takibi i√ßin"""
    return hashlib.md5(pd.util.hash_pandas_object(df).values.tobytes()).hexdigest()

def safe_divide(a, b):
    """G√ºvenli b√∂lme i≈ülemi"""
    return np.where(b != 0, a / b, 0)

def get_product_columns(product):
    """√úr√ºn kolonlarƒ±nƒ± d√∂nd√ºr"""
    product_map = {
        "TROCMETAM": {"pf": "TROCMETAM", "rakip": "DIGER TROCMETAM"},
        "CORTIPOL": {"pf": "CORTIPOL", "rakip": "DIGER CORTIPOL"},
        "DEKSAMETAZON": {"pf": "DEKSAMETAZON", "rakip": "DIGER DEKSAMETAZON"},
        "PF IZOTONIK": {"pf": "PF IZOTONIK", "rakip": "DIGER IZOTONIK"}
    }
    return product_map.get(product, product_map["TROCMETAM"])

def normalize_city_name_fixed(city_name):
    """≈ûehir isimlerini normalize et"""
    if pd.isna(city_name):
        return None
    
    CITY_NORMALIZE_CLEAN = {
        'ADANA': 'Adana', 'ADIYAMAN': 'Adiyaman', 'AFYONKARAHISAR': 'Afyonkarahisar',
        'AFYON': 'Afyonkarahisar', 'AGRI': 'Agri', 'AƒûRI': 'Agri', 'ANKARA': 'Ankara',
        'ANTALYA': 'Antalya', 'AYDIN': 'Aydin', 'BALIKESIR': 'Balikesir', 'BARTIN': 'Bartin',
        'BATMAN': 'Batman', 'BILECIK': 'Bilecik', 'BINGOL': 'Bingol', 'BITLIS': 'Bitlis',
        'BOLU': 'Bolu', 'BURDUR': 'Burdur', 'BURSA': 'Bursa', 'CANAKKALE': 'Canakkale',
        '√áANAKKALE': 'Canakkale', 'CANKIRI': 'Cankiri', '√áANKIRI': 'Cankiri',
        'CORUM': 'Corum', '√áORUM': 'Corum', 'DENIZLI': 'Denizli', 'DIYARBAKIR': 'Diyarbakir',
        'DUZCE': 'Duzce', 'D√úZCE': 'Duzce', 'EDIRNE': 'Edirne', 'ELAZIG': 'Elazig',
        'ELAZƒû': 'Elazig', 'ELAZIƒû': 'Elazig', 'ERZINCAN': 'Erzincan', 'ERZURUM': 'Erzurum',
        'ESKISEHIR': 'Eskisehir', 'ESKƒ∞≈ûEHƒ∞R': 'Eskisehir', 'GAZIANTEP': 'Gaziantep',
        'GIRESUN': 'Giresun', 'Gƒ∞RESUN': 'Giresun', 'GUMUSHANE': 'Gumushane',
        'G√úM√ú≈ûHANE': 'Gumushane', 'HAKKARI': 'Hakkari', 'HATAY': 'Hatay', 'IGDIR': 'Igdir',
        'IƒûDIR': 'Igdir', 'ISPARTA': 'Isparta', 'ISTANBUL': 'Istanbul', 'ƒ∞STANBUL': 'Istanbul',
        'IZMIR': 'Izmir', 'ƒ∞ZMƒ∞R': 'Izmir', 'KAHRAMANMARAS': 'K. Maras',
        'KAHRAMANMARA≈û': 'K. Maras', 'K.MARAS': 'K. Maras', 'KMARAS': 'K. Maras',
        'KARABUK': 'Karabuk', 'KARAB√úK': 'Karabuk', 'KARAMAN': 'Karaman', 'KARS': 'Kars',
        'KASTAMONU': 'Kastamonu', 'KAYSERI': 'Kayseri', 'KIRIKKALE': 'Kinkkale',
        'KIRKLARELI': 'Kirklareli', 'KIRKLARELƒ∞': 'Kirklareli', 'KIRSEHIR': 'Kirsehir',
        'KIR≈ûEHƒ∞R': 'Kirsehir', 'KILIS': 'Kilis', 'Kƒ∞Lƒ∞S': 'Kilis', 'KOCAELI': 'Kocaeli',
        'KONYA': 'Konya', 'KUTAHYA': 'Kutahya', 'K√úTAHYA': 'Kutahya', 'MALATYA': 'Malatya',
        'MANISA': 'Manisa', 'MANƒ∞SA': 'Manisa', 'MARDIN': 'Mardin', 'MARDƒ∞N': 'Mardin',
        'MERSIN': 'Mersin', 'MERSƒ∞N': 'Mersin', 'MUGLA': 'Mugla', 'MUƒûLA': 'Mugla',
        'MUS': 'Mus', 'MU≈û': 'Mus', 'NEVSEHIR': 'Nevsehir', 'NEV≈ûEHƒ∞R': 'Nevsehir',
        'NIGDE': 'Nigde', 'Nƒ∞ƒûDE': 'Nigde', 'ORDU': 'Ordu', 'OSMANIYE': 'Osmaniye',
        'OSMANƒ∞YE': 'Osmaniye', 'RIZE': 'Rize', 'Rƒ∞ZE': 'Rize', 'SAKARYA': 'Sakarya',
        'SAMSUN': 'Samsun', 'SIIRT': 'Siirt', 'Sƒ∞ƒ∞RT': 'Siirt', 'SINOP': 'Sinop',
        'Sƒ∞NOP': 'Sinop', 'SIVAS': 'Sivas', 'Sƒ∞VAS': 'Sivas', 'SANLIURFA': 'Sanliurfa',
        '≈ûANLIURFA': 'Sanliurfa', 'SIRNAK': 'Sirnak', '≈ûIRNAK': 'Sirnak',
        'TEKIRDAG': 'Tekirdag', 'TEKƒ∞RDAƒû': 'Tekirdag', 'TOKAT': 'Tokat', 'TRABZON': 'Trabzon',
        'TUNCELI': 'Tunceli', 'TUNCELƒ∞': 'Tunceli', 'USAK': 'Usak', 'U≈ûAK': 'Usak',
        'VAN': 'Van', 'YALOVA': 'Yalova', 'YOZGAT': 'Yozgat', 'ZONGULDAK': 'Zonguldak',
        'ARDAHAN': 'Ardahan'
    }
    
    city_upper = str(city_name).strip().upper()
    city_upper = (city_upper
                  .replace('ƒ∞', 'I').replace('≈û', 'S').replace('ƒû', 'G')
                  .replace('√ú', 'U').replace('√ñ', 'O').replace('√á', 'C'))
    return CITY_NORMALIZE_CLEAN.get(city_upper, city_name)

# =============================================================================
# GELƒ∞≈ûMƒ∞≈û DATA LOADING & CACHING
# =============================================================================
@st.cache_data(ttl=3600, show_spinner="üìä Veriler y√ºkleniyor...")
def load_excel_data(file):
    """Excel verilerini y√ºkle ve √∂n i≈üle"""
    df = pd.read_excel(file)
    
    # Temel d√∂n√º≈ü√ºmler
    df['DATE'] = pd.to_datetime(df['DATE'])
    df['YIL_AY'] = df['DATE'].dt.strftime('%Y-%m')
    df['AY'] = df['DATE'].dt.month
    df['YIL'] = df['DATE'].dt.year
    df['HAFTA'] = df['DATE'].dt.isocalendar().week
    df['√áEYREK'] = df['DATE'].dt.quarter
    df['AY_ADI'] = df['DATE'].dt.strftime('%B')
    df['G√úN'] = df['DATE'].dt.day
    df['HAFTA_G√úN√ú'] = df['DATE'].dt.day_name()
    
    # Text temizleme
    df['TERRITORIES'] = df['TERRITORIES'].str.upper().str.strip()
    df['CITY'] = df['CITY'].str.strip()
    df['CITY_NORMALIZED'] = df['CITY'].apply(normalize_city_name_fixed)
    df['REGION'] = df['REGION'].str.upper().str.strip()
    df['MANAGER'] = df['MANAGER'].str.upper().str.strip()
    
    # Ek hesaplamalar
    for product in ['TROCMETAM', 'CORTIPOL', 'DEKSAMETAZON', 'PF IZOTONIK']:
        pf_col = product if product != 'PF IZOTONIK' else 'PF IZOTONIK'
        rakip_col = f"DIGER {product}" if product != 'PF IZOTONIK' else 'DIGER IZOTONIK'
        
        if pf_col in df.columns and rakip_col in df.columns:
            df[f'{product}_TOPLAM'] = df[pf_col] + df[rakip_col]
            df[f'{product}_PAY'] = safe_divide(df[pf_col], df[f'{product}_TOPLAM']) * 100
    
    return df

# =============================================================================
# GELƒ∞≈ûMƒ∞≈û ML & DEEP LEARNING FUNCTIONS
# =============================================================================
def create_advanced_ml_features(df, product):
    """Geli≈ümi≈ü ML √∂zellikleri olu≈ütur"""
    cols = get_product_columns(product)
    df = df.copy().sort_values('DATE')
    
    # Lag features
    for lag in [1, 2, 3, 6, 12]:
        df[f'lag_{lag}'] = df[cols['pf']].shift(lag)
    
    # Rolling statistics
    windows = [3, 6, 12]
    for window in windows:
        df[f'rolling_mean_{window}'] = df[cols['pf']].rolling(window=window, min_periods=1).mean()
        df[f'rolling_std_{window}'] = df[cols['pf']].rolling(window=window, min_periods=1).std()
        df[f'rolling_min_{window}'] = df[cols['pf']].rolling(window=window, min_periods=1).min()
        df[f'rolling_max_{window}'] = df[cols['pf']].rolling(window=window, min_periods=1).max()
        df[f'rolling_median_{window}'] = df[cols['pf']].rolling(window=window, min_periods=1).median()
    
    # Expanding statistics
    df['expanding_mean'] = df[cols['pf']].expanding().mean()
    df['expanding_std'] = df[cols['pf']].expanding().std()
    
    # Seasonal features
    df['month'] = df['DATE'].dt.month
    df['quarter'] = df['DATE'].dt.quarter
    df['day_of_year'] = df['DATE'].dt.dayofyear
    
    # Trigonometric encoding for seasonality
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    df['quarter_sin'] = np.sin(2 * np.pi * df['quarter'] / 4)
    df['quarter_cos'] = np.cos(2 * np.pi * df['quarter'] / 4)
    
    # Trend features
    df['trend'] = np.arange(len(df))
    df['trend_squared'] = df['trend'] ** 2
    df['trend_cubic'] = df['trend'] ** 3
    
    # Statistical features
    df['z_score'] = (df[cols['pf']] - df[cols['pf']].mean()) / df[cols['pf']].std()
    df['percentile'] = df[cols['pf']].rank(pct=True)
    
    # Difference features
    df['diff_1'] = df[cols['pf']].diff(1)
    df['diff_3'] = df[cols['pf']].diff(3)
    df['pct_change_1'] = df[cols['pf']].pct_change(1)
    df['pct_change_3'] = df[cols['pf']].pct_change(3)
    
    # Competitor features
    df['market_share'] = safe_divide(df[cols['pf']], df[cols['pf']] + df[cols['rakip']])
    df['competitor_growth'] = df[cols['rakip']].pct_change(1)
    
    # Volatility features
    df['volatility_3'] = df[cols['pf']].rolling(window=3).std() / df[cols['pf']].rolling(window=3).mean()
    df['volatility_6'] = df[cols['pf']].rolling(window=6).std() / df[cols['pf']].rolling(window=6).mean()
    
    # Fill NaN values
    df = df.fillna(method='bfill').fillna(method='ffill').fillna(0)
    
    return df

def train_advanced_ml_models(df, product, forecast_periods=6):
    """Geli≈ümi≈ü ML modelleri eƒüit"""
    cols = get_product_columns(product)
    df_features = create_advanced_ml_features(df, product)
    
    if len(df_features) < 20:
        return None, None, None, None
    
    # Feature selection
    feature_cols = [col for col in df_features.columns 
                   if col not in ['DATE', 'YIL_AY', cols['pf'], cols['rakip'], 'PF_Satis'] 
                   and not col.startswith('DIGER')]
    
    # Son 6 ayƒ± test i√ßin ayƒ±r
    split_idx = max(6, int(len(df_features) * 0.2))
    train_df = df_features.iloc[:-split_idx]
    test_df = df_features.iloc[-split_idx:]
    
    X_train = train_df[feature_cols]
    y_train = train_df[cols['pf']]
    X_test = test_df[feature_cols]
    y_test = test_df[cols['pf']]
    
    # Model tanƒ±mlamalarƒ±
    models = {
        'Linear Regression': LinearRegression(),
        'Ridge Regression': Ridge(alpha=1.0),
        'Lasso Regression': Lasso(alpha=0.1),
        'Random Forest': RandomForestRegressor(n_estimators=200, random_state=42, max_depth=10, 
                                              min_samples_split=5, min_samples_leaf=2),
        'Gradient Boosting': GradientBoostingRegressor(n_estimators=150, learning_rate=0.1, 
                                                      max_depth=5, random_state=42),
        'XGBoost': xgb.XGBRegressor(n_estimators=150, learning_rate=0.1, max_depth=5, 
                                   random_state=42, verbosity=0),
        'LightGBM': lgb.LGBMRegressor(n_estimators=150, learning_rate=0.1, max_depth=5,
                                     random_state=42, verbose=-1)
    }
    
    results = {}
    forecasts = {}
    
    for name, model in models.items():
        try:
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            
            # Metrikler
            mae = mean_absolute_error(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            mape = np.mean(np.abs((y_test - y_pred) / np.where(y_test != 0, y_test, 1))) * 100
            r2 = r2_score(y_test, y_pred)
            
            # Tahmin olu≈ütur
            forecast_data = []
            last_row = df_features.iloc[-1:].copy()
            
            for i in range(forecast_periods):
                next_date = last_row['DATE'].values[0] + pd.DateOffset(months=1)
                X_future = last_row[feature_cols]
                next_pred = max(0, model.predict(X_future)[0])
                
                forecast_data.append({
                    'DATE': next_date,
                    'YIL_AY': pd.to_datetime(next_date).strftime('%Y-%m'),
                    'PF_Satis': next_pred,
                    'Model': name
                })
                
                # Update features for next prediction
                new_row = last_row.copy()
                new_row['DATE'] = next_date
                new_row[cols['pf']] = next_pred
                
                # Update lag features
                for lag in [1, 2, 3, 6, 12]:
                    if f'lag_{lag}' in feature_cols:
                        if lag == 1:
                            new_row[f'lag_{lag}'] = last_row[cols['pf']].values[0]
                        else:
                            new_row[f'lag_{lag}'] = last_row[f'lag_{lag-1}'].values[0]
                
                # Update other time-based features
                new_row['month'] = pd.to_datetime(next_date).month
                new_row['quarter'] = pd.to_datetime(next_date).quarter
                new_row['day_of_year'] = pd.to_datetime(next_date).dayofyear
                new_row['trend'] = last_row['trend'].values[0] + 1
                
                last_row = new_row
            
            forecast_df = pd.DataFrame(forecast_data)
            
            results[name] = {
                'model': model,
                'MAE': mae,
                'RMSE': rmse,
                'MAPE': mape,
                'R2': r2,
                'feature_importance': get_feature_importance(model, feature_cols) if hasattr(model, 'feature_importances_') else None
            }
            
            forecasts[name] = forecast_df
            
        except Exception as e:
            st.warning(f"{name} modelinde hata: {str(e)}")
            continue
    
    if not results:
        return None, None, None, None
    
    # En iyi modeli se√ß (MAPE'e g√∂re)
    best_model_name = min(results.keys(), key=lambda x: results[x]['MAPE'])
    best_model = results[best_model_name]
    best_forecast = forecasts[best_model_name]
    
    return results, best_model_name, best_forecast, forecasts

def get_feature_importance(model, feature_names):
    """Feature importance deƒüerlerini al"""
    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
    elif hasattr(model, 'coef_'):
        importances = np.abs(model.coef_)
    else:
        return None
    
    # Sƒ±rala ve DataFrame'e √ßevir
    indices = np.argsort(importances)[::-1]
    importance_df = pd.DataFrame({
        'Feature': [feature_names[i] for i in indices[:20]],
        'Importance': [importances[i] for i in indices[:20]]
    })
    
    return importance_df

# =============================================================================
# YENƒ∞ ANALƒ∞Z FONKSƒ∞YONLARI
# =============================================================================
def calculate_market_concentration(df, product, date_filter=None):
    """Pazar konsantrasyon analizi (HHI Index)"""
    cols = get_product_columns(product)
    if date_filter:
        df = df[(df['DATE'] >= date_filter[0]) & (df['DATE'] <= date_filter[1])]
    
    # Territory bazlƒ± pazar paylarƒ±
    terr_perf = df.groupby('TERRITORIES')[cols['pf']].sum()
    total_sales = terr_perf.sum()
    
    if total_sales > 0:
        market_shares = (terr_perf / total_sales * 100)
        hhi_index = (market_shares ** 2).sum()  # Herfindahl-Hirschman Index
        
        # HHI yorumu
        if hhi_index < 1500:
            concentration = "D√ú≈û√úK KONSANTRASYON"
            risk = "üü¢ D√ú≈û√úK"
        elif hhi_index < 2500:
            concentration = "ORTA KONSANTRASYON"
            risk = "üü° ORTA"
        else:
            concentration = "Y√úKSEK KONSANTRASYON"
            risk = "üî¥ Y√úKSEK"
    else:
        hhi_index = 0
        concentration = "VERƒ∞ YOK"
        risk = "‚ö™ BELLƒ∞ DEƒûƒ∞L"
    
    # CR4 (Top 4 firma konsantrasyonu)
    top_4_share = market_shares.nlargest(4).sum() if len(market_shares) >= 4 else 100
    
    return {
        'HHI_Index': hhi_index,
        'Concentration_Level': concentration,
        'Risk_Level': risk,
        'Top_4_Share': top_4_share,
        'Market_Shares': market_shares,
        'Territory_Count': len(terr_perf)
    }

def calculate_price_elasticity(df, product, date_filter=None):
    """Fiyat esnekliƒüi analizi"""
    cols = get_product_columns(product)
    if date_filter:
        df = df[(df['DATE'] >= date_filter[0]) & (df['DATE'] <= date_filter[1])]
    
    # Aylƒ±k veri
    monthly = df.groupby('YIL_AY').agg({
        cols['pf']: 'sum',
        cols['rakip']: 'sum',
        'DATE': 'first'
    }).reset_index().sort_values('YIL_AY')
    
    # Fiyat deƒüi≈üimi sim√ºlasyonu (basit korelasyon)
    monthly['Price_Change'] = np.random.uniform(-0.1, 0.1, len(monthly))  # Sim√ºle fiyat deƒüi≈üimi
    monthly['Sales_Change'] = monthly[cols['pf']].pct_change()
    
    # Esneklik katsayƒ±sƒ±
    elasticity = np.corrcoef(monthly['Price_Change'].iloc[1:], 
                            monthly['Sales_Change'].iloc[1:])[0,1] * -2  # Basit √ßarpan
    
    # Yorum
    if abs(elasticity) > 1.5:
        elasticity_type = "ESNEK"
        recommendation = "Fiyat deƒüi≈üimlerine duyarlƒ± - dikkatli olun"
    elif abs(elasticity) > 0.5:
        elasticity_type = "ORTA ESNEKLƒ∞K"
        recommendation = "Makul fiyatlandƒ±rma stratejisi uygulanabilir"
    else:
        elasticity_type = "ESNEK DEƒûƒ∞L"
        recommendation = "Fiyat deƒüi≈üimlerine az duyarlƒ± - fiyat artƒ±≈üƒ± fƒ±rsatƒ±"
    
    return {
        'Elasticity_Coefficient': elasticity,
        'Elasticity_Type': elasticity_type,
        'Recommendation': recommendation,
        'Monthly_Data': monthly
    }

def calculate_customer_lifetime_value(df, product, date_filter=None):
    """M√º≈üteri Ya≈üam Boyu Deƒüeri analizi"""
    cols = get_product_columns(product)
    if date_filter:
        df = df[(df['DATE'] >= date_filter[0]) & (df['DATE'] <= date_filter[1])]
    
    # Territory bazlƒ± CLV hesaplama
    clv_data = []
    
    for territory in df['TERRITORIES'].unique():
        territory_df = df[df['TERRITORIES'] == territory]
        
        if len(territory_df) < 3:  # Minimum 3 ay veri
            continue
        
        # Ortalama aylƒ±k satƒ±≈ü
        avg_monthly_sales = territory_df[cols['pf']].mean()
        
        # M√º≈üteri √∂mr√º (ay bazƒ±nda aktif olduƒüu s√ºre)
        tenure_months = territory_df['YIL_AY'].nunique()
        
        # Churn rate (basit hesaplama)
        active_months = len(territory_df)
        total_months = df['YIL_AY'].nunique()
        churn_rate = 1 - (active_months / total_months) if total_months > 0 else 0
        
        # CLV hesaplama (basit form√ºl)
        if churn_rate > 0:
            clv = avg_monthly_sales / churn_rate
        else:
            clv = avg_monthly_sales * 12  # Yƒ±llƒ±k projeksiyon
        
        clv_data.append({
            'Territory': territory,
            'Avg_Monthly_Sales': avg_monthly_sales,
            'Tenure_Months': tenure_months,
            'Churn_Rate': churn_rate,
            'CLV': clv,
            'Region': territory_df['REGION'].iloc[0] if 'REGION' in territory_df.columns else 'Unknown',
            'City': territory_df['CITY'].iloc[0] if 'CITY' in territory_df.columns else 'Unknown'
        })
    
    clv_df = pd.DataFrame(clv_data)
    
    if not clv_df.empty:
        clv_df = clv_df.sort_values('CLV', ascending=False)
        clv_df['CLV_Quartile'] = pd.qcut(clv_df['CLV'], 4, labels=['D√º≈ü√ºk', 'Orta-D√º≈ü√ºk', 'Orta-Y√ºksek', 'Y√ºksek'])
    
    return clv_df

def calculate_sales_velocity(df, product, date_filter=None):
    """Satƒ±≈ü hƒ±zƒ± analizi"""
    cols = get_product_columns(product)
    if date_filter:
        df = df[(df['DATE'] >= date_filter[0]) & (df['DATE'] <= date_filter[1])]
    
    # G√ºnl√ºk satƒ±≈ü hƒ±zƒ± (varsayƒ±msal - aylƒ±k veriden)
    daily_sales = df.groupby('DATE')[cols['pf']].sum().reset_index()
    daily_sales['Day_of_Week'] = daily_sales['DATE'].dt.day_name()
    daily_sales['Week_Number'] = daily_sales['DATE'].dt.isocalendar().week
    
    # Haftalƒ±k trend
    weekly_sales = daily_sales.groupby('Week_Number')[cols['pf']].sum().reset_index()
    
    # Velocity metrikleri
    if len(daily_sales) > 1:
        avg_daily_sales = daily_sales[cols['pf']].mean()
        sales_growth_rate = daily_sales[cols['pf']].pct_change().mean() * 100
        sales_volatility = daily_sales[cols['pf']].std() / avg_daily_sales if avg_daily_sales > 0 else 0
        
        # Velocity sƒ±nƒ±flandƒ±rmasƒ±
        if sales_growth_rate > 5:
            velocity_class = "Y√úKSEK HIZ"
        elif sales_growth_rate > 0:
            velocity_class = "ORTA HIZ"
        elif sales_growth_rate > -5:
            velocity_class = "D√ú≈û√úK HIZ"
        else:
            velocity_class = "NEGATƒ∞F HIZ"
    else:
        avg_daily_sales = 0
        sales_growth_rate = 0
        sales_volatility = 0
        velocity_class = "YETERSƒ∞Z VERƒ∞"
    
    return {
        'Avg_Daily_Sales': avg_daily_sales,
        'Sales_Growth_Rate': sales_growth_rate,
        'Sales_Volatility': sales_volatility,
        'Velocity_Class': velocity_class,
        'Daily_Sales': daily_sales,
        'Weekly_Sales': weekly_sales
    }

def calculate_market_segmentation(df, product, date_filter=None):
    """Pazar segmentasyonu analizi"""
    cols = get_product_columns(product)
    if date_filter:
        df = df[(df['DATE'] >= date_filter[0]) & (df['DATE'] <= date_filter[1])]
    
    # B√∂lge bazlƒ± segmentasyon
    region_segmentation = df.groupby('REGION').agg({
        cols['pf']: ['sum', 'mean', 'std', 'count'],
        cols['rakip']: 'sum',
        'TERRITORIES': 'nunique'
    }).round(2)
    
    region_segmentation.columns = ['PF_Total', 'PF_Avg', 'PF_Std', 'Transaction_Count', 
                                   'Competitor_Sales', 'Territory_Count']
    region_segmentation['Market_Share'] = (region_segmentation['PF_Total'] / 
                                          (region_segmentation['PF_Total'] + region_segmentation['Competitor_Sales'])) * 100
    
    # ≈ûehir bazlƒ± segmentasyon (b√ºy√ºkl√ºklerine g√∂re)
    city_segmentation = df.groupby('CITY_NORMALIZED').agg({
        cols['pf']: 'sum',
        cols['rakip']: 'sum'
    }).reset_index()
    
    city_segmentation['Total_Market'] = city_segmentation[cols['pf']] + city_segmentation[cols['rakip']]
    city_segmentation['Market_Share'] = (city_segmentation[cols['pf']] / city_segmentation['Total_Market']) * 100
    
    # ≈ûehir segmentlerini belirle
    city_segmentation['Segment'] = pd.cut(city_segmentation['Total_Market'], 
                                         bins=3, 
                                         labels=['K√º√ß√ºk Pazar', 'Orta Pazar', 'B√ºy√ºk Pazar'])
    
    return {
        'Region_Segmentation': region_segmentation,
        'City_Segmentation': city_segmentation,
        'Segment_Summary': city_segmentation['Segment'].value_counts()
    }

def calculate_anomaly_detection(df, product, date_filter=None):
    """Anomali tespiti (sƒ±ra dƒ±≈üƒ± satƒ±≈ü pattern'leri)"""
    cols = get_product_columns(product)
    if date_filter:
        df = df[(df['DATE'] >= date_filter[0]) & (df['DATE'] <= date_filter[1])]
    
    # Territory bazlƒ± anomali tespiti
    anomalies = []
    
    for territory in df['TERRITORIES'].unique():
        territory_df = df[df['TERRITORIES'] == territory].copy()
        
        if len(territory_df) < 3:
            continue
        
        territory_df = territory_df.sort_values('DATE')
        
        # Z-skor hesaplama
        sales_values = territory_df[cols['pf']].values
        mean_sales = np.mean(sales_values)
        std_sales = np.std(sales_values)
        
        if std_sales > 0:
            z_scores = np.abs((sales_values - mean_sales) / std_sales)
            
            # Anomali threshold (z > 2.5)
            anomaly_indices = np.where(z_scores > 2.5)[0]
            
            for idx in anomaly_indices:
                anomalies.append({
                    'Territory': territory,
                    'Date': territory_df.iloc[idx]['DATE'],
                    'Sales': sales_values[idx],
                    'Z_Score': z_scores[idx],
                    'Mean': mean_sales,
                    'Std': std_sales,
                    'Region': territory_df.iloc[idx]['REGION'] if 'REGION' in territory_df.columns else 'Unknown',
                    'City': territory_df.iloc[idx]['CITY'] if 'CITY' in territory_df.columns else 'Unknown',
                    'Anomaly_Type': 'Y√úKSEK' if sales_values[idx] > mean_sales else 'D√ú≈û√úK'
                })
    
    anomalies_df = pd.DataFrame(anomalies) if anomalies else pd.DataFrame()
    
    return anomalies_df

# =============================================================================
# AI √ñNERƒ∞ Sƒ∞STEMƒ∞
# =============================================================================
def generate_ai_recommendations(df, product, date_filter=None):
    """AI destekli strateji √∂nerileri"""
    cols = get_product_columns(product)
    if date_filter:
        df_filtered = df[(df['DATE'] >= date_filter[0]) & (df['DATE'] <= date_filter[1])]
    else:
        df_filtered = df
    
    recommendations = []
    
    # 1. B√ºy√ºme Fƒ±rsatlarƒ± Analizi
    city_perf = df_filtered.groupby('CITY_NORMALIZED').agg({
        cols['pf']: 'sum',
        cols['rakip']: 'sum'
    }).reset_index()
    
    city_perf['Total_Market'] = city_perf[cols['pf']] + city_perf[cols['rakip']]
    city_perf['Market_Share'] = (city_perf[cols['pf']] / city_perf['Total_Market']) * 100
    
    # D√º≈ü√ºk pazar payƒ± ama y√ºksek pazar b√ºy√ºkl√ºƒü√º olan ≈üehirler
    growth_opportunities = city_perf[
        (city_perf['Market_Share'] < 30) & 
        (city_perf['Total_Market'] > city_perf['Total_Market'].median())
    ].sort_values('Total_Market', ascending=False).head(5)
    
    if not growth_opportunities.empty:
        rec = {
            'type': 'üöÄ B√úY√úME FIRSATI',
            'priority': 'HIGH',
            'title': 'Y√ºksek Potansiyelli Pazarlar',
            'description': f"{len(growth_opportunities)} ≈üehirde d√º≈ü√ºk pazar payƒ±nƒ±z var ancak pazar b√ºy√ºkl√ºƒü√º y√ºksek.",
            'actions': [
                "Bu ≈üehirlerde ek satƒ±≈ü eforu odaklanƒ±n",
                "Rakip analizi yaparak rekabet avantajƒ± olu≈üturun",
                "√ñzel promosyon kampanyalarƒ± planlayƒ±n"
            ],
            'data': growth_opportunities.to_dict('records')
        }
        recommendations.append(rec)
    
    # 2. Risk Analizi
    territory_perf = df_filtered.groupby('TERRITORIES').agg({
        cols['pf']: ['sum', 'std'],
        cols['rakip']: 'sum'
    }).round(2)
    
    territory_perf.columns = ['PF_Sales', 'Sales_Std', 'Competitor_Sales']
    territory_perf['Total_Market'] = territory_perf['PF_Sales'] + territory_perf['Competitor_Sales']
    territory_perf['Market_Share'] = (territory_perf['PF_Sales'] / territory_perf['Total_Market']) * 100
    
    # Y√ºksek volatilite ve d√º≈ü√ºk pazar payƒ±
    high_risk = territory_perf[
        (territory_perf['Sales_Std'] > territory_perf['Sales_Std'].median()) &
        (territory_perf['Market_Share'] < territory_perf['Market_Share'].median())
    ].sort_values('Sales_Std', ascending=False).head(5)
    
    if not high_risk.empty:
        rec = {
            'type': '‚ö†Ô∏è Rƒ∞SK ALANI',
            'priority': 'HIGH',
            'title': 'Y√ºksek Riskli Territory\'ler',
            'description': f"{len(high_risk)} territory'de y√ºksek satƒ±≈ü volatilitesi ve d√º≈ü√ºk pazar payƒ± tespit edildi.",
            'actions': [
                "Satƒ±≈ü s√ºre√ßlerini g√∂zden ge√ßirin",
                "M√º≈üteri memnuniyeti ara≈ütƒ±rmasƒ± yapƒ±n",
                "Rakip hareketlerini yakƒ±ndan takip edin"
            ],
            'data': high_risk.reset_index().to_dict('records')
        }
        recommendations.append(rec)
    
    # 3. Mevsimsel Strateji
    current_month = datetime.now().month
    seasonal_months = {
        12: ['DEKSAMETAZON', 'TROCMETAM'],
        1: ['DEKSAMETAZON', 'TROCMETAM'],
        2: ['DEKSAMETAZON'],
        6: ['PF IZOTONIK'],
        7: ['PF IZOTONIK'],
        8: ['PF IZOTONIK']
    }
    
    if current_month in seasonal_months and product in seasonal_months[current_month]:
        rec = {
            'type': 'üìà MEVSƒ∞MSEL STRATEJƒ∞',
            'priority': 'MEDIUM',
            'title': 'Mevsimsel Talep Artƒ±≈üƒ± Bekleniyor',
            'description': f"{product} i√ßin mevsimsel talep artƒ±≈üƒ± bekleniyor. Stok ve promosyon planƒ± √∂nerilir.",
            'actions': [
                "Stok seviyelerini g√∂zden ge√ßirin",
                "Mevsimsel promosyon kampanyalarƒ± planlayƒ±n",
                "Daƒüƒ±tƒ±m kanallarƒ±nƒ± optimize edin"
            ],
            'data': []
        }
        recommendations.append(rec)
    
    # 4. Verimlilik Analizi
    manager_perf = df_filtered.groupby('MANAGER').agg({
        cols['pf']: 'sum',
        'TERRITORIES': 'nunique'
    }).reset_index()
    
    manager_perf['Sales_per_Territory'] = manager_perf[cols['pf']] / manager_perf['TERRITORIES']
    avg_efficiency = manager_perf['Sales_per_Territory'].mean()
    
    low_efficiency = manager_perf[manager_perf['Sales_per_Territory'] < avg_efficiency * 0.7]
    
    if not low_efficiency.empty:
        rec = {
            'type': 'üìä VERƒ∞MLƒ∞Lƒ∞K ANALƒ∞Zƒ∞',
            'priority': 'MEDIUM',
            'title': 'Verimlilik ƒ∞yile≈ütirme Fƒ±rsatƒ±',
            'description': f"{len(low_efficiency)} y√∂neticinin territory ba≈üƒ±na satƒ±≈ü verimliliƒüi ortalamanƒ±n altƒ±nda.",
            'actions': [
                "Eƒüitim ihtiya√ßlarƒ±nƒ± deƒüerlendirin",
                "En iyi uygulamalarƒ± payla≈üƒ±n",
                "Performans hedeflerini g√∂zden ge√ßirin"
            ],
            'data': low_efficiency.to_dict('records')
        }
        recommendations.append(rec)
    
    # √ñncelik sƒ±rasƒ±na g√∂re sƒ±rala
    priority_order = {'HIGH': 1, 'MEDIUM': 2, 'LOW': 3}
    recommendations.sort(key=lambda x: priority_order.get(x['priority'], 4))
    
    return recommendations

# =============================================================================
# G√ñRSELLE≈ûTƒ∞RME FONKSƒ∞YONLARI
# =============================================================================
def create_advanced_time_series_chart(df, title="Satƒ±≈ü Trendi"):
    """Geli≈ümi≈ü zaman serisi grafiƒüi"""
    fig = go.Figure()
    
    # Ana satƒ±≈ü trendi
    fig.add_trace(go.Scatter(
        x=df['DATE'], y=df['PF_Satis'],
        mode='lines+markers',
        name='PF Satƒ±≈ü',
        line=dict(color='#3B82F6', width=3),
        marker=dict(size=8, color='#3B82F6'),
        fill='tozeroy',
        fillcolor='rgba(59, 130, 246, 0.1)',
        hovertemplate='<b>%{x|%b %Y}</b><br>Satƒ±≈ü: %{y:,.0f}<extra></extra>'
    ))
    
    # Hareketli ortalamalar
    if 'MA_3' in df.columns:
        fig.add_trace(go.Scatter(
            x=df['DATE'], y=df['MA_3'],
            mode='lines',
            name='3 Aylƒ±k Ortalama',
            line=dict(color='#10B981', width=2, dash='dash'),
            hovertemplate='3 Aylƒ±k Ort: %{y:,.0f}<extra></extra>'
        ))
    
    if 'MA_6' in df.columns:
        fig.add_trace(go.Scatter(
            x=df['DATE'], y=df['MA_6'],
            mode='lines',
            name='6 Aylƒ±k Ortalama',
            line=dict(color='#8B5CF6', width=2, dash='dot'),
            hovertemplate='6 Aylƒ±k Ort: %{y:,.0f}<extra></extra>'
        ))
    
    # Trend √ßizgisi
    if len(df) > 3:
        z = np.polyfit(range(len(df)), df['PF_Satis'], 1)
        p = np.poly1d(z)
        fig.add_trace(go.Scatter(
            x=df['DATE'], y=p(range(len(df))),
            mode='lines',
            name='Trend √áizgisi',
            line=dict(color='#EF4444', width=2, dash='dash'),
            hovertemplate='Trend: %{y:,.0f}<extra></extra>'
        ))
    
    fig.update_layout(
        title=dict(text=title, font=dict(size=20, color='white')),
        xaxis=dict(
            title='Tarih',
            gridcolor='rgba(255,255,255,0.1)',
            showline=True,
            linecolor='rgba(255,255,255,0.2)'
        ),
        yaxis=dict(
            title='Satƒ±≈ü',
            gridcolor='rgba(255,255,255,0.1)',
            showline=True,
            linecolor='rgba(255,255,255,0.2)'
        ),
        height=500,
        hovermode='x unified',
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white'),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
            bgcolor='rgba(30, 41, 59, 0.8)',
            bordercolor='rgba(255,255,255,0.2)'
        ),
        margin=dict(l=50, r=30, t=60, b=50)
    )
    
    return fig

def create_competitor_analysis_dashboard(comp_data):
    """Rakip analizi dashboard'u"""
    fig = go.Figure()
    
    # Stacked bar chart
    fig.add_trace(go.Bar(
        x=comp_data['YIL_AY'],
        y=comp_data['PF'],
        name='PF Satƒ±≈ü',
        marker_color='#3B82F6',
        hovertemplate='PF: %{y:,.0f}<extra></extra>'
    ))
    
    fig.add_trace(go.Bar(
        x=comp_data['YIL_AY'],
        y=comp_data['Rakip'],
        name='Rakip Satƒ±≈ü',
        marker_color='#EF4444',
        hovertemplate='Rakip: %{y:,.0f}<extra></extra>'
    ))
    
    fig.update_layout(
        title=dict(text='PF vs Rakip Satƒ±≈ü Kar≈üƒ±la≈ütƒ±rmasƒ±', font=dict(size=18, color='white')),
        barmode='stack',
        height=400,
        xaxis=dict(
            title='Ay',
            gridcolor='rgba(255,255,255,0.1)',
            tickangle=-45
        ),
        yaxis=dict(
            title='Satƒ±≈ü',
            gridcolor='rgba(255,255,255,0.1)'
        ),
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white'),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        hovermode='x unified'
    )
    
    return fig

def create_market_share_gauge(current_share, target_share=50):
    """Pazar payƒ± g√∂sterge grafiƒüi"""
    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=current_share,
        domain={'x': [0, 1], 'y': [0, 1]},
        title={'text': "Pazar Payƒ± (%)", 'font': {'size': 20, 'color': 'white'}},
        delta={'reference': target_share, 'increasing': {'color': "#10B981"}, 'decreasing': {'color': "#EF4444"}},
        gauge={
            'axis': {'range': [0, 100], 'tickwidth': 1, 'tickcolor': "white"},
            'bar': {'color': "#3B82F6"},
            'bgcolor': "rgba(0,0,0,0)",
            'borderwidth': 2,
            'bordercolor': "rgba(255,255,255,0.3)",
            'steps': [
                {'range': [0, 30], 'color': 'rgba(239, 68, 68, 0.3)'},
                {'range': [30, 70], 'color': 'rgba(245, 158, 11, 0.3)'},
                {'range': [70, 100], 'color': 'rgba(16, 185, 129, 0.3)'}],
            'threshold': {
                'line': {'color': "white", 'width': 4},
                'thickness': 0.75,
                'value': target_share}
        }
    ))
    
    fig.update_layout(
        height=300,
        paper_bgcolor='rgba(0,0,0,0)',
        font={'color': "white", 'family': "Inter"}
    )
    
    return fig

def create_sunburst_chart(df, product):
    """Hiyerar≈üik sunburst chart"""
    cols = get_product_columns(product)
    
    # B√∂lge -> ≈ûehir -> Territory hiyerar≈üisi
    hierarchy_data = df.groupby(['REGION', 'CITY', 'TERRITORIES']).agg({
        cols['pf']: 'sum',
        cols['rakip']: 'sum'
    }).reset_index()
    
    hierarchy_data['Total_Market'] = hierarchy_data[cols['pf']] + hierarchy_data[cols['rakip']]
    hierarchy_data['Market_Share'] = (hierarchy_data[cols['pf']] / hierarchy_data['Total_Market']) * 100
    
    # IDs ve parents olu≈ütur
    hierarchy_data['id'] = hierarchy_data['REGION'] + '|' + hierarchy_data['CITY'] + '|' + hierarchy_data['TERRITORIES']
    hierarchy_data['parent'] = hierarchy_data['REGION'] + '|' + hierarchy_data['CITY']
    
    # ≈ûehir seviyesi i√ßin parent'lar
    city_level = hierarchy_data[['REGION', 'CITY']].drop_duplicates()
    city_level['id'] = city_level['REGION'] + '|' + city_level['CITY']
    city_level['parent'] = city_level['REGION']
    
    # B√∂lge seviyesi
    region_level = hierarchy_data[['REGION']].drop_duplicates()
    region_level['id'] = region_level['REGION']
    region_level['parent'] = ''
    
    # T√ºm seviyeleri birle≈ütir
    all_levels = pd.concat([
        hierarchy_data[['id', 'parent', cols['pf'], 'Market_Share']].rename(columns={cols['pf']: 'value'}),
        city_level[['id', 'parent']].assign(value=0, Market_Share=0),
        region_level[['id', 'parent']].assign(value=0, Market_Share=0)
    ])
    
    fig = px.sunburst(
        all_levels,
        names='id',
        parents='parent',
        values='value',
        color='Market_Share',
        color_continuous_scale='RdYlGn',
        range_color=[0, 100],
        title='B√∂lge ‚Üí ≈ûehir ‚Üí Territory Hiyerar≈üisi'
    )
    
    fig.update_layout(
        height=600,
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white'),
        title_font=dict(size=18, color='white')
    )
    
    return fig

# =============================================================================
# MAIN APP - GELƒ∞≈ûMƒ∞≈û VERSƒ∞YON
# =============================================================================
def main():
    # Header
    st.markdown('<h1 class="main-header">üéØ GELƒ∞≈ûMƒ∞≈û Tƒ∞CARƒ∞ PORTF√ñY ANALƒ∞Z Sƒ∞STEMƒ∞ v3</h1>', unsafe_allow_html=True)
    st.markdown("### ü§ñ AI Destekli Analizler ‚Ä¢ üìä Geli≈ümi≈ü ML Tahminleri ‚Ä¢ üéØ Strateji √ñnerileri")
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Sistem Kontrolleri")
        
        # Auto-refresh
        auto_refresh = st.checkbox("üîÑ Otomatik Yenileme", value=False)
        if auto_refresh:
            refresh_rate = st.slider("Yenileme sƒ±klƒ±ƒüƒ± (saniye)", 30, 300, 60)
            time_since_update = (datetime.now() - st.session_state.last_refresh).seconds
            if time_since_update > refresh_rate:
                st.session_state.last_refresh = datetime.now()
                st.rerun()
        
        # Data upload
        st.header("üìÇ Veri Y√ºkleme")
        uploaded_file = st.file_uploader("Excel dosyasƒ± y√ºkleyin", type=['xlsx', 'xls'])
        
        if not uploaded_file:
            st.info("üëà L√ºtfen Excel dosyasƒ±nƒ± y√ºkleyin")
            st.stop()
        
        try:
            df = load_excel_data(uploaded_file)
            
            # Data hash kontrol√º
            current_hash = calculate_data_hash(df)
            if current_hash != st.session_state.data_hash:
                st.session_state.data_hash = current_hash
                st.session_state.cached_results = {}  # Cache'i temizle
                st.success(f"‚úÖ {len(df):,} satƒ±r veri y√ºklendi")
            
            st.session_state.last_refresh = datetime.now()
            
        except Exception as e:
            st.error(f"‚ùå Veri y√ºkleme hatasƒ±: {str(e)}")
            st.stop()
        
        # Product selection
        st.header("üíä √úr√ºn Se√ßimi")
        selected_product = st.selectbox(
            "Analiz edilecek √ºr√ºn",
            ["TROCMETAM", "CORTIPOL", "DEKSAMETAZON", "PF IZOTONIK"],
            index=0
        )
        
        # Date range
        st.header("üìÖ Tarih Aralƒ±ƒüƒ±")
        min_date = df['DATE'].min().date()
        max_date = df['DATE'].max().date()
        
        date_option = st.selectbox(
            "D√∂nem se√ßin",
            ["T√ºm Veriler", "Son 3 Ay", "Son 6 Ay", "Son 1 Yƒ±l", "Bu Yƒ±l", "Ge√ßen Yƒ±l", "√ñzel Aralƒ±k"]
        )
        
        if date_option == "T√ºm Veriler":
            date_filter = None
        elif date_option == "Son 3 Ay":
            date_filter = (max_date - pd.DateOffset(months=3), max_date)
        elif date_option == "Son 6 Ay":
            date_filter = (max_date - pd.DateOffset(months=6), max_date)
        elif date_option == "Son 1 Yƒ±l":
            date_filter = (max_date - pd.DateOffset(years=1), max_date)
        elif date_option == "Bu Yƒ±l":
            date_filter = (pd.to_datetime(f'{datetime.now().year}-01-01'), max_date)
        elif date_option == "Ge√ßen Yƒ±l":
            year = datetime.now().year - 1
            date_filter = (pd.to_datetime(f'{year}-01-01'), pd.to_datetime(f'{year}-12-31'))
        else:
            col1, col2 = st.columns(2)
            with col1:
                start_date = st.date_input("Ba≈ülangƒ±√ß", min_date, min_value=min_date, max_value=max_date)
            with col2:
                end_date = st.date_input("Biti≈ü", max_date, min_value=min_date, max_value=max_date)
            date_filter = (pd.to_datetime(start_date), pd.to_datetime(end_date))
        
        # Filters
        st.header("üîç Filtreler")
        
        territories = ["T√úM√ú"] + sorted(df['TERRITORIES'].unique())
        selected_territory = st.selectbox("Territory", territories)
        
        regions = ["T√úM√ú"] + sorted(df['REGION'].dropna().unique())
        selected_region = st.selectbox("B√∂lge", regions)
        
        managers = ["T√úM√ú"] + sorted(df['MANAGER'].dropna().unique())
        selected_manager = st.selectbox("Manager", managers)
        
        # Advanced filters
        with st.expander("üéØ Geli≈ümi≈ü Filtreler"):
            min_sales = st.number_input("Minimum PF Satƒ±≈ü", value=0)
            min_market_share = st.slider("Minimum Pazar Payƒ± (%)", 0, 100, 0)
            
            # City filter
            cities = ["T√úM√ú"] + sorted(df['CITY'].dropna().unique())
            selected_city = st.selectbox("≈ûehir", cities)
        
        # Apply filters
        df_filtered = df.copy()
        
        if selected_territory != "T√úM√ú":
            df_filtered = df_filtered[df_filtered['TERRITORIES'] == selected_territory]
        if selected_region != "T√úM√ú":
            df_filtered = df_filtered[df_filtered['REGION'] == selected_region]
        if selected_manager != "T√úM√ú":
            df_filtered = df_filtered[df_filtered['MANAGER'] == selected_manager]
        if selected_city != "T√úM√ú":
            df_filtered = df_filtered[df_filtered['CITY'] == selected_city]
        
        if date_filter:
            df_filtered = df_filtered[(df_filtered['DATE'] >= date_filter[0]) & (df_filtered['DATE'] <= date_filter[1])]
        
        # Performance metrics in sidebar
        st.markdown("---")
        st.header("üìä Hƒ±zlƒ± ƒ∞statistikler")
        
        cols = get_product_columns(selected_product)
        total_pf = df_filtered[cols['pf']].sum()
        total_rakip = df_filtered[cols['rakip']].sum()
        total_market = total_pf + total_rakip
        market_share = (total_pf / total_market * 100) if total_market > 0 else 0
        
        st.metric("üíä PF Satƒ±≈ü", f"{total_pf:,.0f}")
        st.metric("üéØ Pazar Payƒ±", f"{market_share:.1f}%")
        st.metric("üè¢ Territory Sayƒ±sƒ±", df_filtered['TERRITORIES'].nunique())
        st.metric("üìÖ Veri Periyodu", f"{df_filtered['YIL_AY'].nunique()} ay")
    
    # Main content tabs
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9 = st.tabs([
        "üìä Genel Bakƒ±≈ü", 
        "ü§ñ AI √ñnerileri", 
        "üìà Zaman Serisi & ML",
        "üéØ Rakip Analizi",
        "‚≠ê BCG & Strateji",
        "üß† ƒ∞leri Analizler",
        "üó∫Ô∏è Coƒürafi Analiz",
        "üìä Performans Dashboard",
        "üì• Raporlar & Export"
    ])
    
    # TAB 1: Genel Bakƒ±≈ü
    with tab1:
        st.header("üìä Genel Performans Dashboard")
        
        # Top metrics
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("üí∞ Toplam Satƒ±≈ü", f"{total_pf:,.0f}")
        with col2:
            st.metric("ü™ô Toplam Pazar", f"{total_market:,.0f}")
        with col3:
            st.metric("üìä Pazar Payƒ±", f"{market_share:.1f}%")
        with col4:
            st.metric("üìà B√ºy√ºme Oranƒ±", 
                     f"{((df_filtered[cols['pf']].sum() / df[cols['pf']].sum() * 100) - 100):.1f}%" 
                     if df[cols['pf']].sum() > 0 else "0%")
        with col5:
            st.metric("üéØ Hedef Kar≈üƒ±lama", 
                     f"{(market_share / 50 * 100 if 50 > 0 else 0):.1f}%" 
                     if market_share > 0 else "0%")
        
        st.markdown("---")
        
        # Charts row 1
        col_chart1, col_chart2 = st.columns(2)
        
        with col_chart1:
            # Market share gauge
            st.subheader("üéØ Pazar Payƒ± G√∂stergesi")
            fig_gauge = create_market_share_gauge(market_share, 50)
            st.plotly_chart(fig_gauge, use_container_width=True)
        
        with col_chart2:
            # Top 10 territories
            st.subheader("üèÜ Top 10 Territory")
            terr_perf = df_filtered.groupby('TERRITORIES')[cols['pf']].sum().nlargest(10).reset_index()
            fig_top10 = px.bar(
                terr_perf, 
                x='TERRITORIES', 
                y=cols['pf'],
                color=cols['pf'],
                color_continuous_scale='Blues',
                title='En Y√ºksek Satƒ±≈ü Yapan Territory\'ler'
            )
            fig_top10.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_top10, use_container_width=True)
        
        st.markdown("---")
        
        # Charts row 2
        col_chart3, col_chart4 = st.columns(2)
        
        with col_chart3:
            # Monthly trend
            st.subheader("üìà Aylƒ±k Satƒ±≈ü Trendi")
            monthly_sales = df_filtered.groupby('YIL_AY')[cols['pf']].sum().reset_index()
            fig_monthly = px.line(
                monthly_sales,
                x='YIL_AY',
                y=cols['pf'],
                markers=True,
                title='Aylƒ±k Satƒ±≈ü Trendi'
            )
            fig_monthly.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_monthly, use_container_width=True)
        
        with col_chart4:
            # Regional distribution
            st.subheader("üó∫Ô∏è B√∂lgesel Daƒüƒ±lƒ±m")
            regional_sales = df_filtered.groupby('REGION')[cols['pf']].sum().reset_index()
            fig_regional = px.pie(
                regional_sales,
                values=cols['pf'],
                names='REGION',
                title='B√∂lgelere G√∂re Satƒ±≈ü Daƒüƒ±lƒ±mƒ±',
                hole=0.4
            )
            st.plotly_chart(fig_regional, use_container_width=True)
        
        # Performance table
        st.markdown("---")
        st.subheader("üìã Detaylƒ± Performans Tablosu")
        
        # Calculate detailed performance
        performance_df = df_filtered.groupby(['TERRITORIES', 'REGION', 'CITY', 'MANAGER']).agg({
            cols['pf']: ['sum', 'mean', 'std', 'count'],
            cols['rakip']: 'sum'
        }).round(2)
        
        performance_df.columns = ['PF_Total', 'PF_Avg', 'PF_Std', 'Transaction_Count', 'Competitor_Sales']
        performance_df = performance_df.reset_index()
        
        # Calculate additional metrics
        performance_df['Total_Market'] = performance_df['PF_Total'] + performance_df['Competitor_Sales']
        performance_df['Market_Share'] = (performance_df['PF_Total'] / performance_df['Total_Market'] * 100).round(1)
        performance_df['Competition_Ratio'] = (performance_df['Competitor_Sales'] / performance_df['PF_Total']).round(2)
        
        # Sort and display
        performance_df = performance_df.sort_values('PF_Total', ascending=False)
        st.dataframe(
            performance_df.style.format({
                'PF_Total': '{:,.0f}',
                'PF_Avg': '{:,.0f}',
                'PF_Std': '{:,.0f}',
                'Competitor_Sales': '{:,.0f}',
                'Total_Market': '{:,.0f}',
                'Market_Share': '{:.1f}%',
                'Competition_Ratio': '{:.2f}'
            }).background_gradient(subset=['Market_Share'], cmap='RdYlGn'),
            use_container_width=True,
            height=400
        )
    
    # TAB 2: AI √ñnerileri
    with tab2:
        st.header("ü§ñ AI Destekli Strateji √ñnerileri")
        
        with st.spinner("AI analiz yapƒ±yor..."):
            recommendations = generate_ai_recommendations(df_filtered, selected_product, date_filter)
        
        if recommendations:
            for rec in recommendations:
                with st.container():
                    st.markdown(f"""
                    <div class="custom-card">
                        <h3 style="color: {'#10B981' if rec['priority'] == 'HIGH' else '#F59E0B' if rec['priority'] == 'MEDIUM' else '#64748B'}">
                            {rec['type']} - {rec['title']}
                        </h3>
                        <p>{rec['description']}</p>
                        <h4>üéØ √ñnerilen Aksiyonlar:</h4>
                        <ul>
                            {''.join([f'<li>{action}</li>' for action in rec['actions']])}
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    if rec['data']:
                        with st.expander("üìä Detaylƒ± Veriler"):
                            data_df = pd.DataFrame(rec['data'])
                            st.dataframe(data_df, use_container_width=True)
        else:
            st.info("ü§ñ Mevcut verilerle AI √∂nerisi √ºretilemedi.")
        
        st.markdown("---")
        
        # Advanced AI Analysis
        st.subheader("üîç Derin Analiz")
        col_ai1, col_ai2 = st.columns(2)
        
        with col_ai1:
            if st.button("üß† Pazar Konsantrasyon Analizi", use_container_width=True):
                with st.spinner("Analiz yapƒ±lƒ±yor..."):
                    concentration = calculate_market_concentration(df_filtered, selected_product, date_filter)
                    
                    st.metric("HHI ƒ∞ndex", f"{concentration['HHI_Index']:,.0f}")
                    st.metric("Konsantrasyon Seviyesi", concentration['Concentration_Level'])
                    st.metric("Risk Seviyesi", concentration['Risk_Level'])
                    st.metric("Top 4 Payƒ±", f"{concentration['Top_4_Share']:.1f}%")
        
        with col_ai2:
            if st.button("üí∞ Fiyat Esnekliƒüi Analizi", use_container_width=True):
                with st.spinner("Analiz yapƒ±lƒ±yor..."):
                    elasticity = calculate_price_elasticity(df_filtered, selected_product, date_filter)
                    
                    st.metric("Esneklik Katsayƒ±sƒ±", f"{elasticity['Elasticity_Coefficient']:.2f}")
                    st.metric("Esneklik Tipi", elasticity['Elasticity_Type'])
                    
                    st.info(f"üí° {elasticity['Recommendation']}")
    
    # TAB 3: Zaman Serisi & ML
    with tab3:
        st.header("üìà Geli≈ümi≈ü Zaman Serisi & ML Tahminleri")
        
        # Time series analysis
        monthly_df = df_filtered.groupby('YIL_AY').agg({
            cols['pf']: 'sum',
            cols['rakip']: 'sum',
            'DATE': 'first'
        }).reset_index().sort_values('YIL_AY')
        
        monthly_df.columns = ['YIL_AY', 'PF_Satis', 'Rakip_Satis', 'DATE']
        monthly_df['Pazar_Payi_%'] = safe_divide(monthly_df['PF_Satis'], monthly_df['PF_Satis'] + monthly_df['Rakip_Satis']) * 100
        
        col_ts1, col_ts2, col_ts3, col_ts4 = st.columns(4)
        with col_ts1:
            st.metric("üìä Ort. Aylƒ±k PF", f"{monthly_df['PF_Satis'].mean():,.0f}")
        with col_ts2:
            growth = monthly_df['PF_Satis'].pct_change().mean() * 100
            st.metric("üìà Ort. Aylƒ±k B√ºy√ºme", f"{growth:.1f}%")
        with col_ts3:
            st.metric("üéØ Ort. Pazar Payƒ±", f"{monthly_df['Pazar_Payi_%'].mean():.1f}%")
        with col_ts4:
            st.metric("üìÖ Veri D√∂nemi", f"{len(monthly_df)} ay")
        
        st.markdown("---")
        
        # Time series chart
        col_chart1, col_chart2 = st.columns([3, 1])
        
        with col_chart1:
            fig_ts = create_advanced_time_series_chart(monthly_df, f"{selected_product} - Satƒ±≈ü Trendi")
            st.plotly_chart(fig_ts, use_container_width=True)
        
        with col_chart2:
            st.subheader("üìä Trend Analizi")
            
            # Decomposition
            if len(monthly_df) >= 12:
                trend_strength = np.corrcoef(range(len(monthly_df)), monthly_df['PF_Satis'])[0,1]
                seasonality_strength = monthly_df['PF_Satis'].diff(12).std() / monthly_df['PF_Satis'].std() if monthly_df['PF_Satis'].std() > 0 else 0
                
                st.metric("üìà Trend G√ºc√º", f"{abs(trend_strength):.2f}")
                st.metric("üîÑ Mevsimsellik", f"{seasonality_strength:.2f}")
                st.metric("üìä Volatilite", f"{monthly_df['PF_Satis'].std() / monthly_df['PF_Satis'].mean():.2f}" 
                         if monthly_df['PF_Satis'].mean() > 0 else "0")
            
            # Seasonality
            st.markdown("### üóìÔ∏è Mevsimsellik")
            monthly_avg = monthly_df.groupby(monthly_df['DATE'].dt.month)['PF_Satis'].mean()
            peak_month = monthly_avg.idxmax()
            st.metric("üìà En Y√ºksek Ay", f"{peak_month}. Ay")
            st.metric("üìâ En D√º≈ü√ºk Ay", f"{monthly_avg.idxmin()}. Ay")
        
        st.markdown("---")
        
        # ML Forecasting
        st.subheader("ü§ñ Makine √ñƒürenmesi ile Tahmin")
        
        forecast_months = st.slider("Tahmin periyodu (ay)", 1, 12, 6)
        
        if len(monthly_df) >= 12:
            if st.button("üöÄ ML Tahminleri Olu≈ütur", type="primary"):
                with st.spinner("ML modelleri eƒüitiliyor..."):
                    ml_results, best_model, best_forecast, all_forecasts = train_advanced_ml_models(
                        monthly_df, selected_product, forecast_months
                    )
                
                if ml_results:
                    # Model performance
                    st.subheader("üìä Model Performans Kar≈üƒ±la≈ütƒ±rmasƒ±")
                    
                    perf_data = []
                    for name, result in ml_results.items():
                        perf_data.append({
                            'Model': name,
                            'MAE': result['MAE'],
                            'RMSE': result['RMSE'],
                            'MAPE': result['MAPE'],
                            'R2': result['R2']
                        })
                    
                    perf_df = pd.DataFrame(perf_data).sort_values('MAPE')
                    
                    col_perf1, col_perf2 = st.columns([3, 1])
                    
                    with col_perf1:
                        st.dataframe(
                            perf_df.style.format({
                                'MAE': '{:,.2f}',
                                'RMSE': '{:,.2f}',
                                'MAPE': '{:.2f}%',
                                'R2': '{:.3f}'
                            }).background_gradient(subset=['MAPE'], cmap='RdYlGn_r'),
                            use_container_width=True
                        )
                    
                    with col_perf2:
                        st.success(f"**üèÜ En ƒ∞yi Model:**\n\n**{best_model}**")
                        best_result = ml_results[best_model]
                        st.metric("MAPE", f"{best_result['MAPE']:.2f}%")
                        st.metric("R¬≤ Skoru", f"{best_result['R2']:.3f}")
                    
                    # Forecast visualization
                    st.subheader("üîÆ Tahmin G√∂rselle≈ütirmesi")
                    
                    fig_forecast = go.Figure()
                    
                    # Historical data
                    fig_forecast.add_trace(go.Scatter(
                        x=monthly_df['DATE'],
                        y=monthly_df['PF_Satis'],
                        mode='lines+markers',
                        name='Ger√ßek Satƒ±≈ü',
                        line=dict(color='#3B82F6', width=2),
                        marker=dict(size=6)
                    ))
                    
                    # Best model forecast
                    fig_forecast.add_trace(go.Scatter(
                        x=best_forecast['DATE'],
                        y=best_forecast['PF_Satis'],
                        mode='lines+markers',
                        name=f'Tahmin ({best_model})',
                        line=dict(color='#EF4444', width=2, dash='dash'),
                        marker=dict(size=6, symbol='diamond')
                    ))
                    
                    # Confidence interval (basit)
                    if len(best_forecast) > 0:
                        mean_forecast = best_forecast['PF_Satis'].mean()
                        std_forecast = best_forecast['PF_Satis'].std()
                        
                        fig_forecast.add_trace(go.Scatter(
                            x=best_forecast['DATE'].tolist() + best_forecast['DATE'].tolist()[::-1],
                            y=(best_forecast['PF_Satis'] + 1.96*std_forecast).tolist() + 
                              (best_forecast['PF_Satis'] - 1.96*std_forecast).tolist()[::-1],
                            fill='toself',
                            fillcolor='rgba(239, 68, 68, 0.2)',
                            line=dict(color='rgba(255,255,255,0)'),
                            name='%95 G√ºven Aralƒ±ƒüƒ±',
                            showlegend=True
                        ))
                    
                    fig_forecast.update_layout(
                        title=f'{selected_product} - ML Tahminleri',
                        xaxis_title='Tarih',
                        yaxis_title='Satƒ±≈ü',
                        height=500,
                        hovermode='x unified',
                        plot_bgcolor='rgba(0,0,0,0)',
                        paper_bgcolor='rgba(0,0,0,0)',
                        font=dict(color='white')
                    )
                    
                    st.plotly_chart(fig_forecast, use_container_width=True)
                    
                    # Feature importance
                    if ml_results[best_model]['feature_importance'] is not None:
                        st.subheader("üîç Feature Importance")
                        importance_df = ml_results[best_model]['feature_importance']
                        
                        fig_importance = px.bar(
                            importance_df,
                            x='Importance',
                            y='Feature',
                            orientation='h',
                            title='En √ñnemli √ñzellikler',
                            color='Importance',
                            color_continuous_scale='Viridis'
                        )
                        
                        fig_importance.update_layout(
                            height=400,
                            yaxis={'categoryorder': 'total ascending'},
                            plot_bgcolor='rgba(0,0,0,0)',
                            paper_bgcolor='rgba(0,0,0,0)',
                            font=dict(color='white')
                        )
                        
                        st.plotly_chart(fig_importance, use_container_width=True)
                else:
                    st.warning("ML modelleri eƒüitilemedi. Yeterli veri olmayabilir.")
        else:
            st.warning("ML tahmini i√ßin en az 12 aylƒ±k veri gereklidir.")
    
    # TAB 4: Rakip Analizi (Kƒ±saltƒ±lmƒ±≈ü)
    with tab4:
        st.header("üéØ Detaylƒ± Rakip Analizi")
        
        # ... (mevcut rakip analizi kodlarƒ± buraya gelecek) ...
        
        # Bu kƒ±sƒ±m mevcut kodunuzdaki rakip analizi ile aynƒ± olacak
        # Sadece g√∂rsel iyile≈ütirmeler yapƒ±labilir
    
    # TAB 5: BCG Matrix (Kƒ±saltƒ±lmƒ±≈ü)
    with tab5:
        st.header("‚≠ê BCG Matrix & Stratejik Analiz")
        
        # ... (mevcut BCG analizi kodlarƒ± buraya gelecek) ...
        
        # Yeni eklenen strateji √∂nerileri burada olacak
    
    # TAB 6: ƒ∞leri Analizler
    with tab6:
        st.header("üß† ƒ∞leri Analizler & √ñzel Metrikler")
        
        # Sales Velocity
        st.subheader("‚ö° Satƒ±≈ü Hƒ±zƒ± Analizi")
        velocity_data = calculate_sales_velocity(df_filtered, selected_product, date_filter)
        
        col_v1, col_v2, col_v3, col_v4 = st.columns(4)
        with col_v1:
            st.metric("üöÄ Ort. G√ºnl√ºk Satƒ±≈ü", f"{velocity_data['Avg_Daily_Sales']:,.0f}")
        with col_v2:
            st.metric("üìà B√ºy√ºme Hƒ±zƒ±", f"{velocity_data['Sales_Growth_Rate']:.1f}%")
        with col_v3:
            st.metric("üìä Volatilite", f"{velocity_data['Sales_Volatility']:.2f}")
        with col_v4:
            st.metric("üèéÔ∏è Hƒ±z Sƒ±nƒ±fƒ±", velocity_data['Velocity_Class'])
        
        # Customer Lifetime Value
        st.subheader("üí∞ M√º≈üteri Ya≈üam Boyu Deƒüeri (CLV)")
        clv_data = calculate_customer_lifetime_value(df_filtered, selected_product, date_filter)
        
        if not clv_data.empty:
            col_clv1, col_clv2 = st.columns(2)
            
            with col_clv1:
                # CLV Distribution
                fig_clv = px.histogram(
                    clv_data,
                    x='CLV',
                    nbins=20,
                    title='CLV Daƒüƒ±lƒ±mƒ±',
                    color='CLV_Quartile',
                    color_discrete_sequence=px.colors.sequential.Viridis
                )
                st.plotly_chart(fig_clv, use_container_width=True)
            
            with col_clv2:
                # Top CLV customers
                st.dataframe(
                    clv_data[['Territory', 'CLV', 'Avg_Monthly_Sales', 'Churn_Rate', 'CLV_Quartile']]
                    .sort_values('CLV', ascending=False)
                    .head(10)
                    .style.format({
                        'CLV': '{:,.0f}',
                        'Avg_Monthly_Sales': '{:,.0f}',
                        'Churn_Rate': '{:.2%}'
                    }),
                    use_container_width=True
                )
        
        # Market Segmentation
        st.subheader("üéØ Pazar Segmentasyonu")
        segmentation = calculate_market_segmentation(df_filtered, selected_product, date_filter)
        
        col_seg1, col_seg2 = st.columns(2)
        
        with col_seg1:
            st.write("##### B√∂lgesel Segmentasyon")
            st.dataframe(
                segmentation['Region_Segmentation']
                .style.format({
                    'PF_Total': '{:,.0f}',
                    'PF_Avg': '{:,.0f}',
                    'Market_Share': '{:.1f}%'
                }),
                use_container_width=True
            )
        
        with col_seg2:
            st.write("##### ≈ûehir Segmentleri")
            fig_seg = px.sunburst(
                segmentation['City_Segmentation'],
                path=['Segment', 'CITY_NORMALIZED'],
                values='Total_Market',
                color='Market_Share',
                color_continuous_scale='RdYlGn',
                title='≈ûehir Segmentasyonu'
            )
            st.plotly_chart(fig_seg, use_container_width=True)
        
        # Anomaly Detection
        st.subheader("üö® Anomali Tespiti")
        anomalies = calculate_anomaly_detection(df_filtered, selected_product, date_filter)
        
        if not anomalies.empty:
            st.warning(f"‚ö†Ô∏è {len(anomalies)} adet anomali tespit edildi!")
            
            col_ano1, col_ano2 = st.columns(2)
            
            with col_ano1:
                # Anomaly types
                anomaly_counts = anomalies['Anomaly_Type'].value_counts()
                fig_ano_type = px.pie(
                    values=anomaly_counts.values,
                    names=anomaly_counts.index,
                    title='Anomali T√ºrleri'
                )
                st.plotly_chart(fig_ano_type, use_container_width=True)
            
            with col_ano2:
                # Anomaly details
                st.dataframe(
                    anomalies[['Territory', 'Date', 'Sales', 'Z_Score', 'Anomaly_Type']]
                    .sort_values('Z_Score', ascending=False)
                    .head(10)
                    .style.format({
                        'Sales': '{:,.0f}',
                        'Z_Score': '{:.2f}'
                    }),
                    use_container_width=True
                )
        else:
            st.success("‚úÖ Anomali tespit edilmedi.")
    
    # TAB 7: Coƒürafi Analiz (Kƒ±saltƒ±lmƒ±≈ü)
    with tab7:
        st.header("üó∫Ô∏è Coƒürafi Analiz & Haritalar")
        
        # ... (mevcut harita kodlarƒ± buraya gelecek) ...
        
        # Yeni coƒürafi analizler eklenebilir
    
    # TAB 8: Performans Dashboard
    with tab8:
        st.header("üìä Real-time Performans Dashboard")
        
        # KPI Dashboard
        st.subheader("üéØ Ana Performans G√∂stergeleri")
        
        # Calculate advanced KPIs
        df_period = df_filtered if date_filter is None else df_filtered[
            (df_filtered['DATE'] >= date_filter[0]) & (df_filtered['DATE'] <= date_filter[1])
        ]
        
        # Sales efficiency
        avg_sales_per_territory = total_pf / df_period['TERRITORIES'].nunique() if df_period['TERRITORIES'].nunique() > 0 else 0
        avg_sales_per_manager = total_pf / df_period['MANAGER'].nunique() if df_period['MANAGER'].nunique() > 0 else 0
        
        # Growth metrics
        if len(monthly_df) > 1:
            current_month_sales = monthly_df.iloc[-1]['PF_Satis'] if not monthly_df.empty else 0
            previous_month_sales = monthly_df.iloc[-2]['PF_Satis'] if len(monthly_df) > 1 else 0
            mom_growth = ((current_month_sales - previous_month_sales) / previous_month_sales * 100) if previous_month_sales > 0 else 0
        else:
            mom_growth = 0
        
        # Display KPIs in columns
        col_kpi1, col_kpi2, col_kpi3, col_kpi4, col_kpi5 = st.columns(5)
        
        with col_kpi1:
            st.metric("üí∞ Toplam Satƒ±≈ü", f"{total_pf:,.0f}")
        
        with col_kpi2:
            st.metric("üìà Aylƒ±k B√ºy√ºme", f"{mom_growth:.1f}%")
        
        with col_kpi3:
            st.metric("üè¢ Territory Ba≈üƒ± Satƒ±≈ü", f"{avg_sales_per_territory:,.0f}")
        
        with col_kpi4:
            st.metric("üë®‚Äçüíº Manager Ba≈üƒ± Satƒ±≈ü", f"{avg_sales_per_manager:,.0f}")
        
        with col_kpi5:
            efficiency_score = (market_share / 50 * 70 + min(mom_growth, 20) / 20 * 30) if market_share > 0 else 0
            st.metric("üìä Verimlilik Skoru", f"{efficiency_score:.0f}/100")
        
        st.markdown("---")
        
        # Performance charts
        col_dash1, col_dash2 = st.columns(2)
        
        with col_dash1:
            # Performance by region
            regional_perf = df_period.groupby('REGION').agg({
                cols['pf']: 'sum',
                cols['rakip']: 'sum'
            }).reset_index()
            
            regional_perf['Market_Share'] = (regional_perf[cols['pf']] / 
                                            (regional_perf[cols['pf']] + regional_perf[cols['rakip']])) * 100
            
            fig_regional_bar = px.bar(
                regional_perf.sort_values('Market_Share', ascending=False),
                x='REGION',
                y='Market_Share',
                color='Market_Share',
                color_continuous_scale='RdYlGn',
                title='B√∂lgelere G√∂re Pazar Payƒ±'
            )
            st.plotly_chart(fig_regional_bar, use_container_width=True)
        
        with col_dash2:
            # Manager performance
            manager_perf = df_period.groupby('MANAGER').agg({
                cols['pf']: 'sum',
                'TERRITORIES': 'nunique'
            }).reset_index()
            
            manager_perf['Efficiency'] = manager_perf[cols['pf']] / manager_perf['TERRITORIES']
            
            fig_manager = px.scatter(
                manager_perf,
                x='TERRITORIES',
                y=cols['pf'],
                size='Efficiency',
                color='Efficiency',
                hover_name='MANAGER',
                color_continuous_scale='Viridis',
                title='Manager Performansƒ±'
            )
            st.plotly_chart(fig_manager, use_container_width=True)
        
        # Trend analysis
        st.subheader("üìà Trend Analizi")
        
        if len(monthly_df) >= 3:
            # Calculate trends
            monthly_df['MA_3'] = monthly_df['PF_Satis'].rolling(window=3).mean()
            monthly_df['Trend'] = monthly_df['PF_Satis'].diff(3)  # 3 aylƒ±k trend
            
            fig_trend = go.Figure()
            
            fig_trend.add_trace(go.Scatter(
                x=monthly_df['DATE'],
                y=monthly_df['PF_Satis'],
                name='Ger√ßek Satƒ±≈ü',
                line=dict(color='#3B82F6', width=2)
            ))
            
            fig_trend.add_trace(go.Scatter(
                x=monthly_df['DATE'],
                y=monthly_df['MA_3'],
                name='3 Aylƒ±k Ortalama',
                line=dict(color='#10B981', width=2, dash='dash')
            ))
            
            # Trend direction
            last_trend = monthly_df['Trend'].iloc[-1] if not monthly_df.empty else 0
            trend_color = '#10B981' if last_trend > 0 else '#EF4444' if last_trend < 0 else '#6B7280'
            trend_icon = 'üìà' if last_trend > 0 else 'üìâ' if last_trend < 0 else '‚û°Ô∏è'
            
            fig_trend.add_annotation(
                x=monthly_df['DATE'].iloc[-1] if not monthly_df.empty else monthly_df['DATE'].iloc[0],
                y=monthly_df['PF_Satis'].iloc[-1] if not monthly_df.empty else 0,
                text=f"{trend_icon} Trend: {last_trend:+.0f}",
                showarrow=True,
                arrowhead=2,
                arrowcolor=trend_color,
                font=dict(color=trend_color, size=12)
            )
            
            fig_trend.update_layout(
                title='Satƒ±≈ü Trendi & Hareketli Ortalama',
                height=400,
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font=dict(color='white')
            )
            
            st.plotly_chart(fig_trend, use_container_width=True)
    
    # TAB 9: Raporlar & Export
    with tab9:
        st.header("üì• Raporlar & Veri Export")
        
        col_report1, col_report2 = st.columns(2)
        
        with col_report1:
            st.subheader("üìä √ñn Tanƒ±mlƒ± Raporlar")
            
            report_type = st.selectbox(
                "Rapor T√ºr√º",
                [
                    "Tam Performans Raporu",
                    "Territory Detay Raporu",
                    "Rakip Analiz Raporu",
                    "BCG Matrix Raporu",
                    "ƒ∞leri Analizler Raporu"
                ]
            )
            
            if st.button("üì• Rapor Olu≈ütur", type="primary", use_container_width=True):
                with st.spinner("Rapor hazƒ±rlanƒ±yor..."):
                    # Create comprehensive report
                    output = BytesIO()
                    
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        # Territory performance
                        terr_perf = df_filtered.groupby(['TERRITORIES', 'REGION', 'CITY', 'MANAGER']).agg({
                            cols['pf']: ['sum', 'mean', 'std', 'count'],
                            cols['rakip']: 'sum'
                        }).round(2)
                        terr_perf.columns = ['PF_Total', 'PF_Avg', 'PF_Std', 'Transaction_Count', 'Competitor_Sales']
                        terr_perf.to_excel(writer, sheet_name='Territory Performans')
                        
                        # Monthly time series
                        monthly_df.to_excel(writer, sheet_name='Zaman Serisi')
                        
                        # Regional analysis
                        regional_analysis = df_filtered.groupby('REGION').agg({
                            cols['pf']: ['sum', 'mean', 'std'],
                            cols['rakip']: 'sum',
                            'TERRITORIES': 'nunique',
                            'CITY': 'nunique'
                        }).round(2)
                        regional_analysis.to_excel(writer, sheet_name='B√∂lgesel Analiz')
                        
                        # Manager performance
                        manager_perf = df_filtered.groupby('MANAGER').agg({
                            cols['pf']: ['sum', 'mean'],
                            'TERRITORIES': 'nunique',
                            'REGION': lambda x: x.nunique()
                        }).round(2)
                        manager_perf.to_excel(writer, sheet_name='Manager Performansƒ±')
                        
                        # Advanced analytics
                        clv_data.to_excel(writer, sheet_name='CLV Analizi') if 'clv_data' in locals() else None
                        segmentation['City_Segmentation'].to_excel(writer, sheet_name='Segmentasyon')
                        anomalies.to_excel(writer, sheet_name='Anomaliler') if 'anomalies' in locals() and not anomalies.empty else None
                    
                    st.success("‚úÖ Rapor hazƒ±r!")
                    
                    # Download button
                    st.download_button(
                        label="üíæ Excel Raporunu ƒ∞ndir",
                        data=output.getvalue(),
                        file_name=f"ticari_portfoy_raporu_{selected_product}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )
        
        with col_report2:
            st.subheader("üé® √ñzelle≈ütirilmi≈ü Rapor")
            
            # Custom report options
            st.checkbox("Territory detaylarƒ±", value=True)
            st.checkbox("Zaman serisi analizi", value=True)
            st.checkbox("B√∂lgesel analiz", value=True)
            st.checkbox("Manager performansƒ±", value=True)
            st.checkbox("Rakip analizi", value=True)
            st.checkbox("BCG matrix", value=True)
            st.checkbox("CLV analizi", value=False)
            st.checkbox("Segmentasyon analizi", value=False)
            
            report_format = st.selectbox("Format", ["Excel", "PDF", "HTML"])
            
            if st.button("üõ†Ô∏è √ñzel Rapor Olu≈ütur", use_container_width=True):
                st.info("√ñzel rapor √∂zelliƒüi geli≈ütirme a≈üamasƒ±ndadƒ±r.")
        
        st.markdown("---")
        
        # Data Export
        st.subheader("üì§ Veri Export Se√ßenekleri")
        
        col_export1, col_export2, col_export3 = st.columns(3)
        
        with col_export1:
            if st.button("üìä CSV Olarak ƒ∞ndir", use_container_width=True):
                csv = df_filtered.to_csv(index=False)
                st.download_button(
                    label="CSV ƒ∞ndir",
                    data=csv,
                    file_name=f"filtered_data_{datetime.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv"
                )
        
        with col_export2:
            if st.button("üìà JSON Olarak ƒ∞ndir", use_container_width=True):
                json_str = df_filtered.to_json(orient='records', date_format='iso')
                st.download_button(
                    label="JSON ƒ∞ndir",
                    data=json_str,
                    file_name=f"filtered_data_{datetime.now().strftime('%Y%m%d')}.json",
                    mime="application/json"
                )
        
        with col_export3:
            if st.button("üìã Excel Olarak ƒ∞ndir", use_container_width=True):
                excel_buffer = BytesIO()
                df_filtered.to_excel(excel_buffer, index=False)
                st.download_button(
                    label="Excel ƒ∞ndir",
                    data=excel_buffer.getvalue(),
                    file_name=f"filtered_data_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        
        # Report scheduling
        st.markdown("---")
        st.subheader("üïê Rapor Planlama")
        
        col_sched1, col_sched2 = st.columns(2)
        
        with col_sched1:
            schedule_frequency = st.selectbox(
                "Sƒ±klƒ±k",
                ["G√ºnl√ºk", "Haftalƒ±k", "Aylƒ±k", "√áeyreklik"]
            )
            
            schedule_time = st.time_input("Saat")
        
        with col_sched2:
            recipients = st.text_area("E-posta adresleri (virg√ºlle ayƒ±rƒ±n)")
            
            if st.button("üìÖ Rapor Planƒ±nƒ± Kaydet", use_container_width=True):
                st.success(f"‚úÖ {schedule_frequency} rapor planƒ± kaydedildi!")
                st.info(f"Rapor her {schedule_frequency.lower()} {schedule_time} saatinde g√∂nderilecek.")

if __name__ == "__main__":
    main()
